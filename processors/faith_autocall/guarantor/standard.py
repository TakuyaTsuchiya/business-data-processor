"""
ãƒ•ã‚§ã‚¤ã‚¹ä¿è¨¼äººã‚ªãƒ¼ãƒˆã‚³ãƒ¼ãƒ«å‡¦ç†ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼
çµ±åˆã‚¢ãƒ—ãƒªç”¨ã«ç§»æ¤
"""

import pandas as pd
import io
import sys
import os
from datetime import datetime
from typing import Tuple, List

# å…±é€šå®šç¾©ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
processors_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if processors_dir not in sys.path:
    sys.path.append(processors_dir)
from autocall_common import AUTOCALL_OUTPUT_COLUMNS
from domain.rules.business_rules import CLIENT_IDS, EXCLUDE_AMOUNTS
from processors.common.detailed_logger import DetailedLogger


def read_csv_auto_encoding(file_content: bytes) -> pd.DataFrame:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°åˆ¤å®šã§èª­ã¿è¾¼ã¿"""
    encodings = ['utf-8', 'utf-8-sig', 'shift_jis', 'cp932']
    
    for enc in encodings:
        try:
            return pd.read_csv(io.BytesIO(file_content), encoding=enc, dtype=str)
        except Exception:
            continue
    
    raise ValueError("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


def apply_faith_guarantor_filters(df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:
    """
    ãƒ•ã‚§ã‚¤ã‚¹ä¿è¨¼äººãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†
    
    ğŸ“‹ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶:
    - å§”è¨—å…ˆæ³•äººID: 1,2,3,4ã®ã¿ï¼ˆãƒ•ã‚§ã‚¤ã‚¹ç®¡ç†æ¡ˆä»¶ï¼‰
    - å…¥é‡‘äºˆå®šæ—¥: å‰æ—¥ä»¥å‰ã¾ãŸã¯NaNï¼ˆå½“æ—¥ã¯é™¤å¤–ï¼‰
    - å…¥é‡‘äºˆå®šé‡‘é¡: 2,3,5ã‚’é™¤å¤–ï¼ˆæ‰‹æ•°æ–™é–¢é€£ï¼‰
    - å›åãƒ©ãƒ³ã‚¯: æ­»äº¡æ±ºå®šã€ç ´ç”£æ±ºå®šã€å¼è­·å£«ä»‹å…¥ã‚’é™¤å¤–
    - TELæºå¸¯.1: ç©ºã§ãªã„å€¤ã®ã¿ï¼ˆä¿è¨¼äººé›»è©±ç•ªå·å¿…é ˆï¼‰
    """
    logs = []
    original_count = len(df)
    logs.append(DetailedLogger.log_initial_load(original_count))
    
    # ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ã®é©ç”¨
    # 1. å§”è¨—å…ˆæ³•äººIDã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆ1,2,3,4ã®ã¿ï¼‰
    df["å§”è¨—å…ˆæ³•äººID"] = pd.to_numeric(df["å§”è¨—å…ˆæ³•äººID"], errors="coerce")
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[~df["å§”è¨—å…ˆæ³•äººID"].isin(CLIENT_IDS['faith'])]
    detail_log = DetailedLogger.log_exclusion_details(
        excluded_data, 
        df.columns.get_loc("å§”è¨—å…ˆæ³•äººID"),
        "å§”è¨—å…ˆæ³•äººID", 
        'id'
    )
    if detail_log:
        logs.append(detail_log)
    
    df = df[df["å§”è¨—å…ˆæ³•äººID"].isin(CLIENT_IDS['faith'])]
    logs.append(DetailedLogger.log_filter_result(before_filter, len(df), "å§”è¨—å…ˆæ³•äººID"))
    
    # 2. å…¥é‡‘äºˆå®šæ—¥ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå‰æ—¥ä»¥å‰ã¾ãŸã¯NaNã€å½“æ—¥ã¯é™¤å¤–ï¼‰
    today = pd.Timestamp.now().normalize()
    df["å…¥é‡‘äºˆå®šæ—¥"] = pd.to_datetime(df["å…¥é‡‘äºˆå®šæ—¥"], errors='coerce')
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[~(df["å…¥é‡‘äºˆå®šæ—¥"].isna() | (df["å…¥é‡‘äºˆå®šæ—¥"] < today))]
    detail_log = DetailedLogger.log_exclusion_details(
        excluded_data,
        df.columns.get_loc("å…¥é‡‘äºˆå®šæ—¥"),
        "å…¥é‡‘äºˆå®šæ—¥",
        'date'
    )
    if detail_log:
        logs.append(detail_log)
    
    df = df[df["å…¥é‡‘äºˆå®šæ—¥"].isna() | (df["å…¥é‡‘äºˆå®šæ—¥"] < today)]
    logs.append(DetailedLogger.log_filter_result(before_filter, len(df), "å…¥é‡‘äºˆå®šæ—¥"))
    
    # 3. å…¥é‡‘äºˆå®šé‡‘é¡ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆ2,3,5ã‚’é™¤å¤–ï¼‰
    df["å…¥é‡‘äºˆå®šé‡‘é¡"] = pd.to_numeric(df["å…¥é‡‘äºˆå®šé‡‘é¡"], errors='coerce')
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[df["å…¥é‡‘äºˆå®šé‡‘é¡"].isin(EXCLUDE_AMOUNTS['faith'])]
    detail_log = DetailedLogger.log_exclusion_details(
        excluded_data,
        df.columns.get_loc("å…¥é‡‘äºˆå®šé‡‘é¡"),
        "å…¥é‡‘äºˆå®šé‡‘é¡",
        'amount'
    )
    if detail_log:
        logs.append(detail_log)
    
    df = df[df["å…¥é‡‘äºˆå®šé‡‘é¡"].isna() | ~df["å…¥é‡‘äºˆå®šé‡‘é¡"].isin(EXCLUDE_AMOUNTS['faith'])]
    logs.append(DetailedLogger.log_filter_result(before_filter, len(df), "å…¥é‡‘äºˆå®šé‡‘é¡"))
    
    # 4. å›åãƒ©ãƒ³ã‚¯ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæ­»äº¡æ±ºå®šã€ç ´ç”£æ±ºå®šã€å¼è­·å£«ä»‹å…¥ã‚’é™¤å¤–ï¼‰
    exclude_ranks = ["æ­»äº¡æ±ºå®š", "ç ´ç”£æ±ºå®š", "å¼è­·å£«ä»‹å…¥"]
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[df["å›åãƒ©ãƒ³ã‚¯"].isin(exclude_ranks)]
    detail_log = DetailedLogger.log_exclusion_details(
        excluded_data,
        df.columns.get_loc("å›åãƒ©ãƒ³ã‚¯"),
        "å›åãƒ©ãƒ³ã‚¯",
        'category'
    )
    if detail_log:
        logs.append(detail_log)

    df = df[~df["å›åãƒ©ãƒ³ã‚¯"].isin(exclude_ranks)]
    logs.append(DetailedLogger.log_filter_result(before_filter, len(df), "å›åãƒ©ãƒ³ã‚¯"))

    # 5. æ»ç´æ®‹å‚µã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆ1å††ä»¥ä¸Šã®ã¿å¯¾è±¡ï¼‰
    df["æ»ç´æ®‹å‚µ"] = pd.to_numeric(
        df["æ»ç´æ®‹å‚µ"].astype(str).str.replace(',', ''),
        errors='coerce'
    )
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[~(df["æ»ç´æ®‹å‚µ"] >= 1)]
    detail_log = DetailedLogger.log_exclusion_details(
        excluded_data,
        df.columns.get_loc("æ»ç´æ®‹å‚µ"),
        "æ»ç´æ®‹å‚µ",
        'amount'
    )
    if detail_log:
        logs.append(detail_log)

    df = df[df["æ»ç´æ®‹å‚µ"] >= 1]
    logs.append(DetailedLogger.log_filter_result(before_filter, len(df), "æ»ç´æ®‹å‚µï¼ˆ1å††ä»¥ä¸Šï¼‰"))

    # 6. TELæºå¸¯.1ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆä¿è¨¼äººé›»è©±ç•ªå·ãŒå¿…é ˆï¼‰
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[~(df["TELæºå¸¯.1"].notna() &
                        (~df["TELæºå¸¯.1"].astype(str).str.strip().isin(["", "nan", "NaN"])))]
    detail_log = DetailedLogger.log_exclusion_details(
        excluded_data,
        df.columns.get_loc("TELæºå¸¯.1"),
        "ä¿è¨¼äººé›»è©±",
        'phone'
    )
    if detail_log:
        logs.append(detail_log)

    df = df[
        df["TELæºå¸¯.1"].notna() &
        (~df["TELæºå¸¯.1"].astype(str).str.strip().isin(["", "nan", "NaN"]))
    ]
    logs.append(DetailedLogger.log_filter_result(before_filter, len(df), "TELæºå¸¯.1"))

    return df, logs


def create_faith_guarantor_output(df_filtered: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:
    """ãƒ•ã‚§ã‚¤ã‚¹ä¿è¨¼äººå‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆ28åˆ—çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰"""
    logs = []
    
    # 28åˆ—ã®çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§åˆæœŸåŒ–
    df_output = pd.DataFrame(index=range(len(df_filtered)), columns=AUTOCALL_OUTPUT_COLUMNS)
    df_output = df_output.fillna("")
    
    # å‡ºåŠ›ç”¨ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    mapping_rules = {
        "é›»è©±ç•ªå·": "TELæºå¸¯.1",
        "æ¶é›»ç•ªå·": "TELæºå¸¯.1",
        "å…¥å±…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "å…¥å±…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
        "æ»ç´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "æ»ç´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
        "ç®¡ç†ç•ªå·": "ç®¡ç†ç•ªå·",
        "å¥‘ç´„è€…åï¼ˆã‚«ãƒŠï¼‰": "å¥‘ç´„è€…ã‚«ãƒŠ",  # ä¿è¨¼äººã§ã‚‚å¥‘ç´„è€…åã‚’å…¥ã‚Œã‚‹
        "ç‰©ä»¶å": "ç‰©ä»¶å",
        "æ®‹å‚µ": "æ»ç´æ®‹å‚µ"
    }
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
    for i, (_, row) in enumerate(df_filtered.iterrows()):
        # åŸºæœ¬ãƒãƒƒãƒ”ãƒ³ã‚°
        for output_col, input_col in mapping_rules.items():
            if output_col in df_output.columns and input_col in row:
                df_output.at[i, output_col] = str(row[input_col]) if pd.notna(row[input_col]) else ""
        
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆ—ã®ç”Ÿæˆï¼ˆãƒ•ã‚§ã‚¤ã‚¹1, ãƒ•ã‚§ã‚¤ã‚¹2, ãƒ•ã‚§ã‚¤ã‚¹3, ãƒ•ã‚§ã‚¤ã‚¹4ï¼‰
        if "å§”è¨—å…ˆæ³•äººID" in row and pd.notna(row["å§”è¨—å…ˆæ³•äººID"]):
            df_output.at[i, "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"] = f"ãƒ•ã‚§ã‚¤ã‚¹{int(row['å§”è¨—å…ˆæ³•äººID'])}"
        else:
            df_output.at[i, "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"] = ""
    
    logs.append(f"ä¿è¨¼äººå‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ä½œæˆå®Œäº†: {len(df_output)}ä»¶")
    
    return df_output, logs


def process_faith_guarantor_data(file_content: bytes) -> Tuple[pd.DataFrame, pd.DataFrame, List[str], str]:
    """
    ãƒ•ã‚§ã‚¤ã‚¹ä¿è¨¼äººãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ãƒ¡ã‚¤ãƒ³é–¢æ•°
    
    Args:
        file_content: ContractListã®ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹
        
    Returns:
        tuple: (ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿DF, å‡ºåŠ›DF, å‡¦ç†ãƒ­ã‚°, å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å)
    """
    try:
        logs = []
        
        # 1. CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        logs.append("ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿é–‹å§‹")
        df_input = read_csv_auto_encoding(file_content)
        logs.append(f"èª­ã¿è¾¼ã¿å®Œäº†: {len(df_input)}ä»¶")
        
        # å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯
        required_columns = ["å§”è¨—å…ˆæ³•äººID", "TELæºå¸¯.1", "å›åãƒ©ãƒ³ã‚¯"]
        missing_columns = [col for col in required_columns if col not in df_input.columns]
        if missing_columns:
            raise ValueError(f"å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_columns}")
        
        # 2. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†
        df_filtered, filter_logs = apply_faith_guarantor_filters(df_input)
        logs.extend(filter_logs)
        
        # 3. å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        df_output, output_logs = create_faith_guarantor_output(df_filtered)
        logs.extend(output_logs)
        
        # 4. å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        today_str = datetime.now().strftime("%m%d")
        output_filename = f"{today_str}ãƒ•ã‚§ã‚¤ã‚¹_ä¿è¨¼äºº.csv"
        
        return df_output, logs, output_filename
        
    except Exception as e:
        raise Exception(f"ãƒ•ã‚§ã‚¤ã‚¹ä¿è¨¼äººãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")


def get_sample_template() -> pd.DataFrame:
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¿”ã™ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"""
    columns = [
        "é›»è©±ç•ªå·", "æ¶é›»ç•ªå·", "å…¥å±…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "æ»ç´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
        "ç®¡ç†ç•ªå·", "å¥‘ç´„è€…åï¼ˆã‚«ãƒŠï¼‰", "ç‰©ä»¶å", "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"
    ]
    return pd.DataFrame(columns=columns)
"""
ãƒ•ã‚§ã‚¤ã‚¹å¥‘ç´„è€…ã‚ªãƒ¼ãƒˆã‚³ãƒ¼ãƒ«å‡¦ç†ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼
çµ±åˆã‚¢ãƒ—ãƒªç”¨ã«ç§»æ¤
"""

import pandas as pd
import io
import sys
import os
from datetime import datetime
from typing import Tuple, List

# å…±é€šå®šç¾©ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
processors_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if processors_dir not in sys.path:
    sys.path.append(processors_dir)
from autocall_common import AUTOCALL_OUTPUT_COLUMNS
from domain.rules.business_rules import CLIENT_IDS, EXCLUDE_AMOUNTS


def read_csv_auto_encoding(file_content: bytes) -> pd.DataFrame:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°åˆ¤å®šã§èª­ã¿è¾¼ã¿"""
    encodings = ['utf-8', 'utf-8-sig', 'shift_jis', 'cp932']
    
    for enc in encodings:
        try:
            return pd.read_csv(io.BytesIO(file_content), encoding=enc, dtype=str)
        except Exception:
            continue
    
    raise ValueError("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


def apply_faith_contract_filters(df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:
    """
    ãƒ•ã‚§ã‚¤ã‚¹å¥‘ç´„è€…ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†
    
    ğŸ“‹ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶:
    - å§”è¨—å…ˆæ³•äººID: 1,2,3,4ã®ã¿ï¼ˆãƒ•ã‚§ã‚¤ã‚¹ç®¡ç†æ¡ˆä»¶ï¼‰
    - å…¥é‡‘äºˆå®šæ—¥: å‰æ—¥ä»¥å‰ã¾ãŸã¯NaNï¼ˆå½“æ—¥ã¯é™¤å¤–ï¼‰
    - å…¥é‡‘äºˆå®šé‡‘é¡: 2,3,5ã‚’é™¤å¤–ï¼ˆæ‰‹æ•°æ–™é–¢é€£ï¼‰
    - å›åãƒ©ãƒ³ã‚¯: æ­»äº¡æ±ºå®šã€ç ´ç”£æ±ºå®šã€å¼è­·å£«ä»‹å…¥ã‚’é™¤å¤–
    - TELæºå¸¯: ç©ºã§ãªã„å€¤ã®ã¿ï¼ˆå¥‘ç´„è€…é›»è©±ç•ªå·å¿…é ˆï¼‰
    """
    logs = []
    original_count = len(df)
    logs.append(f"å…ƒãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {original_count}ä»¶")
    
    # ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ã®é©ç”¨
    # 1. å§”è¨—å…ˆæ³•äººIDã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆ1,2,3,4ã®ã¿ï¼‰
    df["å§”è¨—å…ˆæ³•äººID"] = pd.to_numeric(df["å§”è¨—å…ˆæ³•äººID"], errors="coerce")
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[~df["å§”è¨—å…ˆæ³•äººID"].isin(CLIENT_IDS['faith'])]
    if len(excluded_data) > 0:
        excluded_counts = excluded_data['å§”è¨—å…ˆæ³•äººID'].value_counts().to_dict()
        excluded_counts_str = {str(int(k)) if pd.notna(k) else 'ç©ºç™½': v for k, v in excluded_counts.items()}
        logs.append(f"å§”è¨—å…ˆæ³•äººIDé™¤å¤–è©³ç´°: {excluded_counts_str}")
    
    df = df[df["å§”è¨—å…ˆæ³•äººID"].isin(CLIENT_IDS['faith'])]
    logs.append(f"å§”è¨—å…ˆæ³•äººIDãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(df)}ä»¶ (é™¤å¤–: {before_filter - len(df)}ä»¶)")
    
    # 2. å…¥é‡‘äºˆå®šæ—¥ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå‰æ—¥ä»¥å‰ã¾ãŸã¯NaNã€å½“æ—¥ã¯é™¤å¤–ï¼‰
    today = pd.Timestamp.now().normalize()
    df["å…¥é‡‘äºˆå®šæ—¥"] = pd.to_datetime(df["å…¥é‡‘äºˆå®šæ—¥"], errors='coerce')
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[~(df["å…¥é‡‘äºˆå®šæ—¥"].isna() | (df["å…¥é‡‘äºˆå®šæ—¥"] < today))]
    if len(excluded_data) > 0:
        excluded_dates = excluded_data['å…¥é‡‘äºˆå®šæ—¥'].dt.strftime('%Y/%m/%d').value_counts().head(10).to_dict()
        logs.append(f"å…¥é‡‘äºˆå®šæ—¥é™¤å¤–è©³ç´°ï¼ˆä¸Šä½10ä»¶ï¼‰: {excluded_dates}")
        if len(excluded_data) > 10:
            logs.append(f"  â€»ä»–{len(excluded_data) - 10}ä»¶ã®æ—¥ä»˜ã‚‚é™¤å¤–")
    
    df = df[df["å…¥é‡‘äºˆå®šæ—¥"].isna() | (df["å…¥é‡‘äºˆå®šæ—¥"] < today)]
    logs.append(f"å…¥é‡‘äºˆå®šæ—¥ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(df)}ä»¶ (é™¤å¤–: {before_filter - len(df)}ä»¶)")
    
    # 3. å…¥é‡‘äºˆå®šé‡‘é¡ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆ2,3,5ã‚’é™¤å¤–ï¼‰
    df["å…¥é‡‘äºˆå®šé‡‘é¡"] = pd.to_numeric(df["å…¥é‡‘äºˆå®šé‡‘é¡"], errors='coerce')
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[df["å…¥é‡‘äºˆå®šé‡‘é¡"].isin(EXCLUDE_AMOUNTS['faith'])]
    if len(excluded_data) > 0:
        excluded_amounts = excluded_data['å…¥é‡‘äºˆå®šé‡‘é¡'].value_counts().to_dict()
        excluded_amounts_str = {f"{int(k)}å††": v for k, v in excluded_amounts.items() if pd.notna(k)}
        logs.append(f"é™¤å¤–é‡‘é¡è©³ç´°: {excluded_amounts_str}")
    
    df = df[df["å…¥é‡‘äºˆå®šé‡‘é¡"].isna() | ~df["å…¥é‡‘äºˆå®šé‡‘é¡"].isin(EXCLUDE_AMOUNTS['faith'])]
    logs.append(f"å…¥é‡‘äºˆå®šé‡‘é¡ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(df)}ä»¶ (é™¤å¤–: {before_filter - len(df)}ä»¶)")
    
    # 4. å›åãƒ©ãƒ³ã‚¯ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæ­»äº¡æ±ºå®šã€ç ´ç”£æ±ºå®šã€å¼è­·å£«ä»‹å…¥ã‚’é™¤å¤–ï¼‰
    exclude_ranks = ["æ­»äº¡æ±ºå®š", "ç ´ç”£æ±ºå®š", "å¼è­·å£«ä»‹å…¥"]
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[df["å›åãƒ©ãƒ³ã‚¯"].isin(exclude_ranks)]
    if len(excluded_data) > 0:
        excluded_ranks_data = excluded_data['å›åãƒ©ãƒ³ã‚¯'].value_counts().to_dict()
        logs.append(f"å›åãƒ©ãƒ³ã‚¯é™¤å¤–è©³ç´°: {excluded_ranks_data}")
    
    df = df[~df["å›åãƒ©ãƒ³ã‚¯"].isin(exclude_ranks)]
    logs.append(f"å›åãƒ©ãƒ³ã‚¯ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(df)}ä»¶ (é™¤å¤–: {before_filter - len(df)}ä»¶)")
    
    # 5. TELæºå¸¯ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå¥‘ç´„è€…TELæºå¸¯ãŒå¿…é ˆï¼‰
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[~(df["TELæºå¸¯"].notna() &
                        (~df["TELæºå¸¯"].astype(str).str.strip().isin(["", "nan", "NaN"])))]
    if len(excluded_data) > 0:
        tel_data = excluded_data['TELæºå¸¯'].astype(str).str.strip()
        empty_count = tel_data[tel_data.isin(['', 'nan', 'NaN'])].count()
        fixed_phone_count = len(excluded_data) - empty_count
        logs.append(f"æºå¸¯é›»è©±é™¤å¤–è©³ç´°: {{ç©ºç™½/NaN: {empty_count}ä»¶, å›ºå®šé›»è©±ç­‰: {fixed_phone_count}ä»¶}}")
    
    df = df[
        df["TELæºå¸¯"].notna() &
        (~df["TELæºå¸¯"].astype(str).str.strip().isin(["", "nan", "NaN"]))
    ]
    logs.append(f"TELæºå¸¯ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(df)}ä»¶ (é™¤å¤–: {before_filter - len(df)}ä»¶)")
    
    return df, logs


def create_faith_contract_output(df_filtered: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:
    """ãƒ•ã‚§ã‚¤ã‚¹å¥‘ç´„è€…å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆ28åˆ—çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰"""
    logs = []
    
    # 28åˆ—ã®çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§åˆæœŸåŒ–
    df_output = pd.DataFrame(index=range(len(df_filtered)), columns=AUTOCALL_OUTPUT_COLUMNS)
    df_output = df_output.fillna("")
    
    # å‡ºåŠ›ç”¨ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæ®‹å‚µãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å‰Šé™¤ï¼‰
    mapping_rules = {
        "é›»è©±ç•ªå·": "TELæºå¸¯",
        "æ¶é›»ç•ªå·": "TELæºå¸¯", 
        "å…¥å±…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "å…¥å±…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
        "æ»ç´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "æ»ç´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
        "ç®¡ç†ç•ªå·": "ç®¡ç†ç•ªå·",
        "å¥‘ç´„è€…åï¼ˆã‚«ãƒŠï¼‰": "å¥‘ç´„è€…ã‚«ãƒŠ",
        "ç‰©ä»¶å": "ç‰©ä»¶å"
        # ã€Œæ®‹å‚µã€åˆ—ã¯ç©ºç™½ã§çµ±ä¸€
    }
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
    for i, (_, row) in enumerate(df_filtered.iterrows()):
        # åŸºæœ¬ãƒãƒƒãƒ”ãƒ³ã‚°
        for output_col, input_col in mapping_rules.items():
            if output_col in df_output.columns and input_col in row:
                df_output.at[i, output_col] = str(row[input_col]) if pd.notna(row[input_col]) else ""
        
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆ—ã®ç”Ÿæˆï¼ˆãƒ•ã‚§ã‚¤ã‚¹1, ãƒ•ã‚§ã‚¤ã‚¹2, ãƒ•ã‚§ã‚¤ã‚¹3, ãƒ•ã‚§ã‚¤ã‚¹4ï¼‰
        if "å§”è¨—å…ˆæ³•äººID" in row and pd.notna(row["å§”è¨—å…ˆæ³•äººID"]):
            df_output.at[i, "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"] = f"ãƒ•ã‚§ã‚¤ã‚¹{int(row['å§”è¨—å…ˆæ³•äººID'])}"
        else:
            df_output.at[i, "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"] = ""
    
    logs.append(f"å¥‘ç´„è€…å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ä½œæˆå®Œäº†: {len(df_output)}ä»¶")
    
    return df_output, logs


def process_faith_contract_data(file_content: bytes) -> Tuple[pd.DataFrame, pd.DataFrame, List[str], str]:
    """
    ãƒ•ã‚§ã‚¤ã‚¹å¥‘ç´„è€…ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ãƒ¡ã‚¤ãƒ³é–¢æ•°
    
    Args:
        file_content: ContractListã®ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹
        
    Returns:
        tuple: (ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿DF, å‡ºåŠ›DF, å‡¦ç†ãƒ­ã‚°, å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å)
    """
    try:
        logs = []
        
        # 1. CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        logs.append("ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿é–‹å§‹")
        df_input = read_csv_auto_encoding(file_content)
        logs.append(f"èª­ã¿è¾¼ã¿å®Œäº†: {len(df_input)}ä»¶")
        
        # å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯
        required_columns = ["å§”è¨—å…ˆæ³•äººID", "TELæºå¸¯", "å›åãƒ©ãƒ³ã‚¯"]
        missing_columns = [col for col in required_columns if col not in df_input.columns]
        if missing_columns:
            raise ValueError(f"å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_columns}")
        
        # 2. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†
        df_filtered, filter_logs = apply_faith_contract_filters(df_input)
        logs.extend(filter_logs)
        
        # 3. å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        df_output, output_logs = create_faith_contract_output(df_filtered)
        logs.extend(output_logs)
        
        # 4. å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        today_str = datetime.now().strftime("%m%d")
        output_filename = f"{today_str}ãƒ•ã‚§ã‚¤ã‚¹_å¥‘ç´„è€….csv"
        
        return df_output, logs, output_filename
        
    except Exception as e:
        raise Exception(f"ãƒ•ã‚§ã‚¤ã‚¹å¥‘ç´„è€…ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")


def get_sample_template() -> pd.DataFrame:
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¿”ã™ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"""
    columns = [
        "é›»è©±ç•ªå·", "æ¶é›»ç•ªå·", "å…¥å±…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "æ»ç´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
        "ç®¡ç†ç•ªå·", "å¥‘ç´„è€…åï¼ˆã‚«ãƒŠï¼‰", "ç‰©ä»¶å", "æ®‹å‚µ", "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"
    ]
    return pd.DataFrame(columns=columns)
"""
ãƒ—ãƒ©ã‚¶å¥‘ç´„è€…ã‚ªãƒ¼ãƒˆã‚³ãƒ¼ãƒ«å‡¦ç†ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼
ãƒŸãƒ©ã‚¤ãƒ«å¥‘ç´„è€…ï¼ˆ10,000å††ã‚’é™¤å¤–ã—ãªã„ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰ãƒ™ãƒ¼ã‚¹ã®å‡¦ç†
ãƒ—ãƒ©ã‚¶å›ºæœ‰æ¡ä»¶ï¼šå§”è¨—å…ˆæ³•äººID=6ã€å…¥é‡‘äºˆå®šæ—¥=å½“æ—¥ä»¥å‰ï¼ˆå½“æ—¥å«ã‚€ï¼‰
"""

import pandas as pd
import io
import sys
import os
from datetime import datetime
from typing import Tuple, List

# å…±é€šå®šç¾©ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
processors_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if processors_dir not in sys.path:
    sys.path.append(processors_dir)
from autocall_common import AUTOCALL_OUTPUT_COLUMNS
from processors.common.detailed_logger import DetailedLogger


def read_csv_auto_encoding(file_content: bytes) -> pd.DataFrame:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°åˆ¤å®šã§èª­ã¿è¾¼ã¿"""
    encodings = ['utf-8', 'utf-8-sig', 'shift_jis', 'cp932']
    
    for enc in encodings:
        try:
            return pd.read_csv(io.BytesIO(file_content), encoding=enc, dtype=str)
        except Exception:
            continue
    
    raise ValueError("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


def apply_plaza_main_filters(df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:
    """
    ãƒ—ãƒ©ã‚¶å¥‘ç´„è€…ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†ï¼ˆãƒŸãƒ©ã‚¤ãƒ«with10kãƒ™ãƒ¼ã‚¹ + ãƒ—ãƒ©ã‚¶å›ºæœ‰æ¡ä»¶ï¼‰
    
    ğŸ“‹ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶:
    - å§”è¨—å…ˆæ³•äººID: 6ã®ã¿ï¼ˆãƒ—ãƒ©ã‚¶å›ºæœ‰ï¼‰
    - å…¥é‡‘äºˆå®šæ—¥: å½“æ—¥ä»¥å‰ã¾ãŸã¯NaNï¼ˆå½“æ—¥ã‚‚å«ã‚€ã€ãƒ—ãƒ©ã‚¶å›ºæœ‰ï¼‰
    - å›åãƒ©ãƒ³ã‚¯: ç£ä¿ƒåœæ­¢ã€å¼è­·å£«ä»‹å…¥ã‚’é™¤å¤–
    - æ®‹å‚µ: ãƒ•ã‚£ãƒ«ã‚¿ãªã—ï¼ˆ10,000å††ãƒ»11,000å††ã‚‚å«ã‚€å…¨ä»¶å‡¦ç†ï¼‰
    - TELæºå¸¯: ç©ºã§ãªã„å€¤ã®ã¿ï¼ˆå¥‘ç´„è€…é›»è©±ç•ªå·ï¼‰
    - å…¥é‡‘äºˆå®šé‡‘é¡: 2,3,5,12å††ã‚’é™¤å¤–ï¼ˆæ‰‹æ•°æ–™é–¢é€£ï¼‰
    """
    logs = []
    original_count = len(df)
    logs.append(DetailedLogger.log_initial_load(original_count))
    
    # ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ã®é©ç”¨
    # 1. å§”è¨—å…ˆæ³•äººIDãŒ6ã®ã¿ï¼ˆãƒ—ãƒ©ã‚¶å›ºæœ‰ï¼‰
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[df["å§”è¨—å…ˆæ³•äººID"].astype(str).str.strip() != "6"]
    if len(excluded_data) > 0:
        logs.append(DetailedLogger.log_exclusion_details(
            excluded_data,
            'å§”è¨—å…ˆæ³•äººID',
            log_type='id'
        ))
    
    df = df[df["å§”è¨—å…ˆæ³•äººID"].astype(str).str.strip() == "6"]
    logs.append(DetailedLogger.log_filter_result(
        "å§”è¨—å…ˆæ³•äººIDï¼ˆ6ã®ã¿ï¼‰",
        before_filter,
        len(df)
    ))
    
    # 2. å…¥é‡‘äºˆå®šæ—¥ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå½“æ—¥ä»¥å‰ã¾ãŸã¯NaNï¼šå½“æ—¥ã‚‚å«ã‚€ï¼‰
    today = pd.Timestamp.now().normalize()
    df["å…¥é‡‘äºˆå®šæ—¥"] = pd.to_datetime(df["å…¥é‡‘äºˆå®šæ—¥"], errors='coerce')
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[~(df["å…¥é‡‘äºˆå®šæ—¥"].isna() | (df["å…¥é‡‘äºˆå®šæ—¥"] <= today))]
    if len(excluded_data) > 0:
        logs.append(DetailedLogger.log_exclusion_details(
            excluded_data,
            'å…¥é‡‘äºˆå®šæ—¥',
            log_type='date'
        ))
    
    df = df[df["å…¥é‡‘äºˆå®šæ—¥"].isna() | (df["å…¥é‡‘äºˆå®šæ—¥"] <= today)]
    logs.append(DetailedLogger.log_filter_result(
        "å…¥é‡‘äºˆå®šæ—¥",
        before_filter,
        len(df)
    ))
    
    # 3. å›åãƒ©ãƒ³ã‚¯ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆç£ä¿ƒåœæ­¢ãƒ»å¼è­·å£«ä»‹å…¥æ¡ˆä»¶ã¯é™¤å¤–ï¼‰
    exclude_ranks = ["ç£ä¿ƒåœæ­¢", "å¼è­·å£«ä»‹å…¥"]
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[df["å›åãƒ©ãƒ³ã‚¯"].isin(exclude_ranks)]
    if len(excluded_data) > 0:
        logs.append(DetailedLogger.log_exclusion_details(
            excluded_data,
            'å›åãƒ©ãƒ³ã‚¯',
            log_type='category'
        ))
    
    df = df[~df["å›åãƒ©ãƒ³ã‚¯"].isin(exclude_ranks)]
    logs.append(DetailedLogger.log_filter_result(
        "å›åãƒ©ãƒ³ã‚¯",
        before_filter,
        len(df)
    ))
    
    # 4. æ®‹å‚µã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆwith10kç‰ˆã§ã¯é™¤å¤–ãªã— - å…¨ä»¶å‡¦ç†ï¼‰
    logs.append("æ®‹å‚µãƒ•ã‚£ãƒ«ã‚¿: é™¤å¤–ãªã—ï¼ˆwith10kç‰ˆï¼š10,000å††ãƒ»11,000å††ã‚‚å«ã‚€å…¨ä»¶å‡¦ç†ï¼‰")
    logs.append("ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆCDãƒ•ã‚£ãƒ«ã‚¿: é™¤å¤–ãªã—ï¼ˆå¥‘ç´„è€…ç‰ˆã¯å…¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå¯¾è±¡ï¼‰")
    
    # 5. TELæºå¸¯ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå¥‘ç´„è€…é›»è©±ç•ªå·ãŒå¿…é ˆï¼‰
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[~(df["TELæºå¸¯"].notna() &
                        (~df["TELæºå¸¯"].astype(str).str.strip().isin(["", "nan", "NaN"])))]
    if len(excluded_data) > 0:
        logs.append(DetailedLogger.log_exclusion_details(
            excluded_data,
            'TELæºå¸¯',
            log_type='phone'
        ))
    
    df = df[
        df["TELæºå¸¯"].notna() &
        (~df["TELæºå¸¯"].astype(str).str.strip().isin(["", "nan", "NaN"]))
    ]
    logs.append(DetailedLogger.log_filter_result(
        "TELæºå¸¯",
        before_filter,
        len(df)
    ))
    
    # 6. å…¥é‡‘äºˆå®šé‡‘é¡ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæ‰‹æ•°æ–™é–¢é€£ã®2,3,5,12å††ã‚’é™¤å¤–ï¼‰
    exclude_amounts = [2, 3, 5, 12]
    df["å…¥é‡‘äºˆå®šé‡‘é¡"] = pd.to_numeric(df["å…¥é‡‘äºˆå®šé‡‘é¡"], errors='coerce')
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[df["å…¥é‡‘äºˆå®šé‡‘é¡"].isin(exclude_amounts)]
    if len(excluded_data) > 0:
        logs.append(DetailedLogger.log_exclusion_details(
            excluded_data,
            'å…¥é‡‘äºˆå®šé‡‘é¡',
            log_type='amount'
        ))
    
    df = df[~df["å…¥é‡‘äºˆå®šé‡‘é¡"].isin(exclude_amounts)]
    logs.append(DetailedLogger.log_filter_result(
        "å…¥é‡‘äºˆå®šé‡‘é¡",
        before_filter,
        len(df)
    ))
    
    return df, logs


def create_plaza_main_output(df_filtered: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:
    """ãƒ—ãƒ©ã‚¶å¥‘ç´„è€…å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆ28åˆ—çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰"""
    logs = []
    
    # 28åˆ—ã®çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§åˆæœŸåŒ–
    df_output = pd.DataFrame(index=range(len(df_filtered)), columns=AUTOCALL_OUTPUT_COLUMNS)
    df_output = df_output.fillna("")
    
    # å‡ºåŠ›ç”¨ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆãƒŸãƒ©ã‚¤ãƒ«with10kã¨åŒã˜ï¼‰
    mapping_rules = {
        "é›»è©±ç•ªå·": "TELæºå¸¯",
        "æ¶é›»ç•ªå·": "TELæºå¸¯", 
        "å…¥å±…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "å…¥å±…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
        "æ»ç´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "æ»ç´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
        "ç®¡ç†ç•ªå·": "ç®¡ç†ç•ªå·",
        "å¥‘ç´„è€…åï¼ˆã‚«ãƒŠï¼‰": "å¥‘ç´„è€…ã‚«ãƒŠ",
        "ç‰©ä»¶å": "ç‰©ä»¶å",
        "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ": "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå",  # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒãƒƒãƒ”ãƒ³ã‚°
        "æ®‹å‚µ": "æ»ç´æ®‹å‚µ"  # Jåˆ—ã€Œæ®‹å‚µã€ã«BTåˆ—ã€Œæ»ç´æ®‹å‚µã€ã‚’æ ¼ç´
    }
    
    # ãƒ‡ãƒ¼ã‚¿ãŒ0ä»¶ã®å ´åˆ
    if len(df_filtered) == 0:
        logs.append("å¥‘ç´„è€…å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ä½œæˆå®Œäº†: 0ä»¶ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰")
        return df_output, logs
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
    for i, (_, row) in enumerate(df_filtered.iterrows()):
        for output_col, input_col in mapping_rules.items():
            if output_col in df_output.columns and input_col in row:
                df_output.at[i, output_col] = str(row[input_col]) if pd.notna(row[input_col]) else ""
    
    logs.append(f"å¥‘ç´„è€…å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ä½œæˆå®Œäº†: {len(df_output)}ä»¶")
    
    return df_output, logs


def process_plaza_main_data(file_content: bytes) -> Tuple[pd.DataFrame, pd.DataFrame, List[str], str]:
    """
    ãƒ—ãƒ©ã‚¶å¥‘ç´„è€…ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ãƒ¡ã‚¤ãƒ³é–¢æ•°
    
    ğŸ“‹ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶:
    - å§”è¨—å…ˆæ³•äººID: 6ã®ã¿ï¼ˆãƒ—ãƒ©ã‚¶å›ºæœ‰ï¼‰
    - å…¥é‡‘äºˆå®šæ—¥: å½“æ—¥ä»¥å‰ã¾ãŸã¯NaNï¼ˆå½“æ—¥ã‚‚å«ã‚€ã€ãƒ—ãƒ©ã‚¶å›ºæœ‰ï¼‰
    - å›åãƒ©ãƒ³ã‚¯: å¼è­·å£«ä»‹å…¥ã‚’é™¤å¤–
    - æ®‹å‚µ: ãƒ•ã‚£ãƒ«ã‚¿ãªã—ï¼ˆ10,000å††ãƒ»11,000å††ã‚‚å«ã‚€å…¨ä»¶å‡¦ç†ï¼‰
    - TELæºå¸¯: ç©ºã§ãªã„å€¤ã®ã¿ï¼ˆå¥‘ç´„è€…é›»è©±ç•ªå·ï¼‰
    - å…¥é‡‘äºˆå®šé‡‘é¡: 2,3,5,12å††ã‚’é™¤å¤–ï¼ˆæ‰‹æ•°æ–™é–¢é€£ï¼‰
    
    Args:
        file_content: ContractListã®ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ï¼ˆbytesï¼‰
        
    Returns:
        tuple: (å‡ºåŠ›DF, ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿DF, å‡¦ç†ãƒ­ã‚°, å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å)
    """
    try:
        logs = []
        
        # 1. CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        logs.append("ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿é–‹å§‹")
        df_input = read_csv_auto_encoding(file_content)
        logs.append(f"èª­ã¿è¾¼ã¿å®Œäº†: {len(df_input)}ä»¶")
        
        # å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯
        required_columns = ["å§”è¨—å…ˆæ³•äººID", "TELæºå¸¯", "å›åãƒ©ãƒ³ã‚¯"]
        missing_columns = [col for col in required_columns if col not in df_input.columns]
        if missing_columns:
            raise ValueError(f"å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_columns}")
        
        # 2. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†
        df_filtered, filter_logs = apply_plaza_main_filters(df_input)
        logs.extend(filter_logs)
        
        # 3. å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        df_output, output_logs = create_plaza_main_output(df_filtered)
        logs.extend(output_logs)
        
        # 4. å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        today_str = datetime.now().strftime("%m%d")
        output_filename = f"{today_str}ãƒ—ãƒ©ã‚¶_å¥‘ç´„è€….csv"
        
        return df_output, logs, output_filename
        
    except Exception as e:
        raise Exception(f"ãƒ—ãƒ©ã‚¶å¥‘ç´„è€…ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")


def get_sample_template() -> pd.DataFrame:
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¿”ã™ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"""
    columns = [
        "é›»è©±ç•ªå·", "æ¶é›»ç•ªå·", "å…¥å±…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "æ»ç´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
        "ç®¡ç†ç•ªå·", "å¥‘ç´„è€…åï¼ˆã‚«ãƒŠï¼‰", "ç‰©ä»¶å", "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"
    ]
    return pd.DataFrame(columns=columns)
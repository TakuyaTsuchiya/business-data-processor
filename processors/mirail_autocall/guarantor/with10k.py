"""
ãƒŸãƒ©ã‚¤ãƒ«ä¿è¨¼äººã‚ªãƒ¼ãƒˆã‚³ãƒ¼ãƒ«å‡¦ç†ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ï¼ˆæ®‹å‚µå«ã‚€å…¨ä»¶ï¼‰
çµ±åˆã‚¢ãƒ—ãƒªç”¨ã«ç§»æ¤
"""

import pandas as pd
import io
import sys
import os
from datetime import datetime
from typing import Tuple, List

# å…±é€šå®šç¾©ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
processors_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if processors_dir not in sys.path:
    sys.path.append(processors_dir)
from autocall_common import AUTOCALL_OUTPUT_COLUMNS


class MirailGuarantorWith10kConfig:
    """ãƒŸãƒ©ã‚¤ãƒ«ä¿è¨¼äººï¼ˆæ®‹å‚µå«ã‚€å…¨ä»¶ï¼‰å‡¦ç†ã®è¨­å®š"""
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ï¼ˆwith10kç‰ˆï¼šæ®‹å‚µãƒ•ã‚£ãƒ«ã‚¿ãªã—ãƒ»ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆCDãƒ•ã‚£ãƒ«ã‚¿ãªã—ï¼‰
    FILTER_CONDITIONS = {
        "å§”è¨—å…ˆæ³•äººID": "ç©ºç™½ã¨5",
        "å…¥é‡‘äºˆå®šæ—¥": "å‰æ—¥ä»¥å‰ã¾ãŸã¯NaN",
        "å›åãƒ©ãƒ³ã‚¯_not_in": ["å¼è­·å£«ä»‹å…¥"],
        "TELæºå¸¯.1": "ç©ºã§ãªã„å€¤ã®ã¿",
        "å…¥é‡‘äºˆå®šé‡‘é¡_not_in": [2, 3, 5, 12]
        # æ³¨æ„ï¼šwith10kç‰ˆã§ã¯æ®‹å‚µãƒ•ã‚£ãƒ«ã‚¿ãƒ»ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆCDãƒ•ã‚£ãƒ«ã‚¿ãªã—ï¼ˆå…¨ä»¶å‡¦ç†ï¼‰
    }
    
    # ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ«ãƒ¼ãƒ«
    MAPPING_RULES = {
        "é›»è©±ç•ªå·": "TELæºå¸¯.1",
        "æ¶é›»ç•ªå·": "TELæºå¸¯.1", 
        "å…¥å±…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "å…¥å±…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
        "æ»ç´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "æ»ç´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
        "ç®¡ç†ç•ªå·": "ç®¡ç†ç•ªå·",
        "å¥‘ç´„è€…åï¼ˆã‚«ãƒŠï¼‰": "å¥‘ç´„è€…ã‚«ãƒŠ",
        "ç‰©ä»¶å": "ç‰©ä»¶å",
        "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ": "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå",
        "æ®‹å‚µ": "æ»ç´æ®‹å‚µ"  # Jåˆ—ã€Œæ®‹å‚µã€ã«BTåˆ—ã€Œæ»ç´æ®‹å‚µã€ã‚’æ ¼ç´
    }
    
    OUTPUT_FILE_PREFIX = "ãƒŸãƒ©ã‚¤ãƒ«_with10k_ä¿è¨¼äºº"


def read_csv_auto_encoding(file_content: bytes) -> pd.DataFrame:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°åˆ¤å®šã§èª­ã¿è¾¼ã¿"""
    encodings = ['utf-8', 'utf-8-sig', 'shift_jis', 'cp932']
    
    for enc in encodings:
        try:
            return pd.read_csv(io.BytesIO(file_content), encoding=enc, dtype=str)
        except Exception:
            continue
    
    raise ValueError("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


def apply_mirail_guarantor_with10k_filters(df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:
    """
    ãƒŸãƒ©ã‚¤ãƒ«ä¿è¨¼äººï¼ˆæ®‹å‚µå«ã‚€ï¼‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†
    
    ğŸ“‹ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ (with10kç‰ˆ):
    - å§”è¨—å…ˆæ³•äººID: ç©ºç™½ã¨5
    - å…¥é‡‘äºˆå®šæ—¥: å‰æ—¥ä»¥å‰ã¾ãŸã¯NaNï¼ˆå½“æ—¥ã¯é™¤å¤–ï¼‰
    - å›åãƒ©ãƒ³ã‚¯: å¼è­·å£«ä»‹å…¥ã‚’é™¤å¤–
    - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆCD: 1ã®ã¿ï¼ˆç‰¹å®šã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã¿ï¼‰
    - æ®‹å‚µå«ã‚€: å…¨ä»¶å‡¦ç†ï¼ˆ10,000å††ãƒ»11,000å††ã‚‚å«ã‚€ï¼‰
    - TELæºå¸¯.1: ç©ºã§ãªã„å€¤ã®ã¿ï¼ˆä¿è¨¼äººé›»è©±ç•ªå·ï¼‰
    
    âš ï¸ without10kç‰ˆã¨ã®é•ã„:
    - without10k: æ®‹å‚µ10,000å††ãƒ»11,000å††ã‚’é™¤å¤–
    - with10k: æ®‹å‚µãƒ•ã‚£ãƒ«ã‚¿ãªã—ï¼ˆå…¨ä»¶å‡¦ç†ï¼‰
    """
    logs = []
    original_count = len(df)
    logs.append(f"å…ƒãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {original_count}ä»¶")
    
    # ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ã®é©ç”¨
    # 1. å§”è¨—å…ˆæ³•äººIDãŒç©ºç™½ã¨5
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[~(df["å§”è¨—å…ˆæ³•äººID"].isna() | 
                        (df["å§”è¨—å…ˆæ³•äººID"].astype(str).str.strip() == "") | 
                        (df["å§”è¨—å…ˆæ³•äººID"].astype(str).str.strip() == "5"))]
    if len(excluded_data) > 0:
        excluded_counts = excluded_data['å§”è¨—å…ˆæ³•äººID'].value_counts().to_dict()
        excluded_counts_str = {str(k): v for k, v in excluded_counts.items()}
        logs.append(f"å§”è¨—å…ˆæ³•äººIDé™¤å¤–è©³ç´°: {excluded_counts_str}")
    
    df = df[df["å§”è¨—å…ˆæ³•äººID"].isna() | 
           (df["å§”è¨—å…ˆæ³•äººID"].astype(str).str.strip() == "") | 
           (df["å§”è¨—å…ˆæ³•äººID"].astype(str).str.strip() == "5")]
    logs.append(f"å§”è¨—å…ˆæ³•äººIDï¼ˆç©ºç™½ã¨5ï¼‰ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(df)}ä»¶ (é™¤å¤–: {before_filter - len(df)}ä»¶)")
    
    # 2. å…¥é‡‘äºˆå®šæ—¥ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå‰æ—¥ä»¥å‰ã¾ãŸã¯NaNï¼šå½“æ—¥ã¯é™¤å¤–ï¼‰
    today = pd.Timestamp.now().normalize()
    df["å…¥é‡‘äºˆå®šæ—¥"] = pd.to_datetime(df["å…¥é‡‘äºˆå®šæ—¥"], errors='coerce')
    before_filter = len(df)
    # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
    excluded_data = df[~(df["å…¥é‡‘äºˆå®šæ—¥"].isna() | (df["å…¥é‡‘äºˆå®šæ—¥"] < today))]
    if len(excluded_data) > 0:
        excluded_dates = excluded_data['å…¥é‡‘äºˆå®šæ—¥'].dt.strftime('%Y/%m/%d').value_counts().head(10).to_dict()
        logs.append(f"å…¥é‡‘äºˆå®šæ—¥é™¤å¤–è©³ç´°ï¼ˆä¸Šä½10ä»¶ï¼‰: {excluded_dates}")
        if len(excluded_data) > 10:
            logs.append(f"  â€»ä»–{len(excluded_data) - 10}ä»¶ã®æ—¥ä»˜ã‚‚é™¤å¤–")
    
    df = df[df["å…¥é‡‘äºˆå®šæ—¥"].isna() | (df["å…¥é‡‘äºˆå®šæ—¥"] < today)]
    logs.append(f"å…¥é‡‘äºˆå®šæ—¥ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(df)}ä»¶ (é™¤å¤–: {before_filter - len(df)}ä»¶)")
    
    # 3. å›åãƒ©ãƒ³ã‚¯ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå¼è­·å£«ä»‹å…¥æ¡ˆä»¶ã¯é™¤å¤–ï¼‰
    if "å›åãƒ©ãƒ³ã‚¯_not_in" in MirailGuarantorWith10kConfig.FILTER_CONDITIONS:
        before_filter = len(df)
        # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
        excluded_data = df[df["å›åãƒ©ãƒ³ã‚¯"].isin(MirailGuarantorWith10kConfig.FILTER_CONDITIONS["å›åãƒ©ãƒ³ã‚¯_not_in"])]
        if len(excluded_data) > 0:
            excluded_ranks = excluded_data['å›åãƒ©ãƒ³ã‚¯'].value_counts().to_dict()
            logs.append(f"å›åãƒ©ãƒ³ã‚¯é™¤å¤–è©³ç´°: {excluded_ranks}")
        
        df = df[~df["å›åãƒ©ãƒ³ã‚¯"].isin(MirailGuarantorWith10kConfig.FILTER_CONDITIONS["å›åãƒ©ãƒ³ã‚¯_not_in"])]
        logs.append(f"å›åãƒ©ãƒ³ã‚¯ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(df)}ä»¶ (é™¤å¤–: {before_filter - len(df)}ä»¶)")
    
    # 4. æ®‹å‚µãƒ»ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆCDã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆwith10kç‰ˆã§ã¯é™¤å¤–ãªã— - å…¨ä»¶å‡¦ç†ï¼‰
    # â€» without10kç‰ˆã§ã¯æ®‹å‚µ10,000å††ãƒ»11,000å††ã‚’é™¤å¤–ã™ã‚‹ãŒã€with10kç‰ˆã¯å…¨ä»¶å‡¦ç†
    # â€» with10kç‰ˆã§ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆCDãƒ•ã‚£ãƒ«ã‚¿ã‚‚é©ç”¨ã—ãªã„ï¼ˆå…¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå¯¾è±¡ï¼‰
    logs.append("æ®‹å‚µãƒ•ã‚£ãƒ«ã‚¿: é™¤å¤–ãªã—ï¼ˆwith10kç‰ˆï¼š10,000å††ãƒ»11,000å††ã‚‚å«ã‚€å…¨ä»¶å‡¦ç†ï¼‰")
    logs.append("ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆCDãƒ•ã‚£ãƒ«ã‚¿: é™¤å¤–ãªã—ï¼ˆwith10kç‰ˆï¼šå…¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå¯¾è±¡ï¼‰")
    
    # 5. å…¥é‡‘äºˆå®šé‡‘é¡ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆ2,3,5,12ã‚’é™¤å¤–ï¼‰
    if "å…¥é‡‘äºˆå®šé‡‘é¡_not_in" in MirailGuarantorWith10kConfig.FILTER_CONDITIONS:
        df["å…¥é‡‘äºˆå®šé‡‘é¡"] = pd.to_numeric(df["å…¥é‡‘äºˆå®šé‡‘é¡"], errors='coerce')
        before_filter = len(df)
        # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
        excluded_data = df[df["å…¥é‡‘äºˆå®šé‡‘é¡"].isin(MirailGuarantorWith10kConfig.FILTER_CONDITIONS["å…¥é‡‘äºˆå®šé‡‘é¡_not_in"])]
        if len(excluded_data) > 0:
            excluded_amounts = excluded_data['å…¥é‡‘äºˆå®šé‡‘é¡'].value_counts().to_dict()
            excluded_amounts_str = {f"{int(k)}å††": v for k, v in excluded_amounts.items() if pd.notna(k)}
            logs.append(f"é™¤å¤–é‡‘é¡è©³ç´°: {excluded_amounts_str}")
        
        df = df[df["å…¥é‡‘äºˆå®šé‡‘é¡"].isna() | ~df["å…¥é‡‘äºˆå®šé‡‘é¡"].isin(MirailGuarantorWith10kConfig.FILTER_CONDITIONS["å…¥é‡‘äºˆå®šé‡‘é¡_not_in"])]
        logs.append(f"å…¥é‡‘äºˆå®šé‡‘é¡ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(df)}ä»¶ (é™¤å¤–: {before_filter - len(df)}ä»¶)")
    
    # 6. TELæºå¸¯.1ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆä¿è¨¼äººé›»è©±ç•ªå·ãŒå¿…é ˆï¼‰
    if "TELæºå¸¯.1" in MirailGuarantorWith10kConfig.FILTER_CONDITIONS:
        before_filter = len(df)
        # é™¤å¤–ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¨˜éŒ²
        excluded_data = df[~(df["TELæºå¸¯.1"].notna() &
                            (~df["TELæºå¸¯.1"].astype(str).str.strip().isin(["", "nan", "NaN"])))]
        if len(excluded_data) > 0:
            tel_data = excluded_data['TELæºå¸¯.1'].astype(str).str.strip()
            empty_count = tel_data[tel_data.isin(['', 'nan', 'NaN'])].count()
            fixed_phone_count = len(excluded_data) - empty_count
            logs.append(f"ä¿è¨¼äººé›»è©±é™¤å¤–è©³ç´°: {{ç©ºç™½/NaN: {empty_count}ä»¶, å›ºå®šé›»è©±ç­‰: {fixed_phone_count}ä»¶}}")
        
        df = df[
            df["TELæºå¸¯.1"].notna() &
            (~df["TELæºå¸¯.1"].astype(str).str.strip().isin(["", "nan", "NaN"]))
        ]
        logs.append(f"TELæºå¸¯.1ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(df)}ä»¶ (é™¤å¤–: {before_filter - len(df)}ä»¶)")
    
    return df, logs


def create_mirail_guarantor_output(df_filtered: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:
    """ãƒŸãƒ©ã‚¤ãƒ«ä¿è¨¼äººå‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆ28åˆ—çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰"""
    logs = []
    
    # 28åˆ—ã®çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§åˆæœŸåŒ–
    df_output = pd.DataFrame(index=range(len(df_filtered)), columns=AUTOCALL_OUTPUT_COLUMNS)
    df_output = df_output.fillna("")
    
    # å‡ºåŠ›ç”¨ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    mapping_rules = {
        "é›»è©±ç•ªå·": "TELæºå¸¯.1",
        "æ¶é›»ç•ªå·": "TELæºå¸¯.1", 
        "å…¥å±…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "å…¥å±…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
        "æ»ç´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "æ»ç´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
        "ç®¡ç†ç•ªå·": "ç®¡ç†ç•ªå·",
        "å¥‘ç´„è€…åï¼ˆã‚«ãƒŠï¼‰": "å¥‘ç´„è€…ã‚«ãƒŠ",  # ä¿è¨¼äººã§ã‚‚å¥‘ç´„è€…åã‚’å…¥ã‚Œã‚‹
        "ç‰©ä»¶å": "ç‰©ä»¶å",
        "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ": "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå",
        "æ®‹å‚µ": "æ»ç´æ®‹å‚µ"  # Jåˆ—ã€Œæ®‹å‚µã€ã«BTåˆ—ã€Œæ»ç´æ®‹å‚µã€ã‚’æ ¼ç´
    }
    
    # ãƒ‡ãƒ¼ã‚¿ãŒ0ä»¶ã®å ´åˆ
    if len(df_filtered) == 0:
        logs.append("ä¿è¨¼äººå‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ä½œæˆå®Œäº†: 0ä»¶ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰")
        return df_output, logs
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
    for i, (_, row) in enumerate(df_filtered.iterrows()):
        for output_col, input_col in mapping_rules.items():
            if output_col in df_output.columns and input_col in row:
                df_output.at[i, output_col] = str(row[input_col]) if pd.notna(row[input_col]) else ""
    
    logs.append(f"ä¿è¨¼äººå‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ä½œæˆå®Œäº†: {len(df_output)}ä»¶")
    
    return df_output, logs


def process_mirail_guarantor_with10k_data(file_content: bytes) -> Tuple[pd.DataFrame, pd.DataFrame, List[str], str]:
    """
    ãƒŸãƒ©ã‚¤ãƒ«ä¿è¨¼äººï¼ˆæ®‹å‚µå«ã‚€ï¼‰ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ãƒ¡ã‚¤ãƒ³é–¢æ•°
    
    ğŸ“‹ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ (with10kç‰ˆ):
    - å§”è¨—å…ˆæ³•äººID: ç©ºç™½ã¨5
    - å…¥é‡‘äºˆå®šæ—¥: å‰æ—¥ä»¥å‰ã¾ãŸã¯NaNï¼ˆå½“æ—¥ã¯é™¤å¤–ï¼‰
    - å›åãƒ©ãƒ³ã‚¯: å¼è­·å£«ä»‹å…¥ã‚’é™¤å¤–
    - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆCD: 1ã®ã¿ï¼ˆç‰¹å®šã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã¿ï¼‰
    - æ®‹å‚µå«ã‚€: å…¨ä»¶å‡¦ç†ï¼ˆ10,000å††ãƒ»11,000å††ã‚‚å«ã‚€ï¼‰
    - TELæºå¸¯.1: ç©ºã§ãªã„å€¤ã®ã¿ï¼ˆä¿è¨¼äººé›»è©±ç•ªå·ï¼‰
    
    âš ï¸ without10kç‰ˆã¨ã®é•ã„:
    - without10k: æ®‹å‚µ10,000å††ãƒ»11,000å††ã‚’é™¤å¤–
    - with10k: æ®‹å‚µãƒ•ã‚£ãƒ«ã‚¿ãªã—ï¼ˆå…¨ä»¶å‡¦ç†ï¼‰
    
    Args:
        file_content: ContractListã®ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ï¼ˆbytesï¼‰
        
    Returns:
        tuple: (å‡ºåŠ›DF, ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿DF, å‡¦ç†ãƒ­ã‚°, å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å)
    """
    try:
        logs = []
        
        # 1. CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆä¿è¨¼äººãƒ‡ãƒ¼ã‚¿ï¼‰
        logs.append("ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿é–‹å§‹")
        df_input = read_csv_auto_encoding(file_content)
        logs.append(f"èª­ã¿è¾¼ã¿å®Œäº†: {len(df_input)}ä»¶")
        
        # ä¿è¨¼äººå‡¦ç†ã«å¿…é ˆãªåˆ—ãƒã‚§ãƒƒã‚¯
        required_columns = ["å§”è¨—å…ˆæ³•äººID", "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆCD", "TELæºå¸¯.1", "å›åãƒ©ãƒ³ã‚¯"]
        missing_columns = [col for col in required_columns if col not in df_input.columns]
        if missing_columns:
            raise ValueError(f"å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_columns}")
        
        # 2. ä¿è¨¼äººãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†
        df_filtered, filter_logs = apply_mirail_guarantor_with10k_filters(df_input)
        logs.extend(filter_logs)
        
        # 3. ä¿è¨¼äººå‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        df_output, output_logs = create_mirail_guarantor_output(df_filtered)
        logs.extend(output_logs)
        
        # 4. ä¿è¨¼äººç”¨å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        today_str = datetime.now().strftime("%m%d")
        output_filename = f"{today_str}ãƒŸãƒ©ã‚¤ãƒ«_with10k_ä¿è¨¼äºº.csv"
        
        return df_output, logs, output_filename
        
    except Exception as e:
        raise Exception(f"ãƒŸãƒ©ã‚¤ãƒ«ä¿è¨¼äººï¼ˆæ®‹å‚µå«ã‚€ï¼‰ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")


def get_sample_template() -> pd.DataFrame:
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¿”ã™ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"""
    columns = [
        "é›»è©±ç•ªå·", "æ¶é›»ç•ªå·", "å…¥å±…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "æ»ç´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
        "ç®¡ç†ç•ªå·", "å¥‘ç´„è€…åï¼ˆã‚«ãƒŠï¼‰", "ç‰©ä»¶å", "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"
    ]
    return pd.DataFrame(columns=columns)
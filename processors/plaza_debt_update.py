"""
ãƒ—ãƒ©ã‚¶æ®‹å‚µæ›´æ–°å‡¦ç†

ãƒ—ãƒ©ã‚¶ã®æ®‹å‚µæ›´æ–°ã«å¿…è¦ãª2ã¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆï¼š
1. ç®¡ç†å‰æ»ç´é¡æƒ…å ±CSV
2. äº¤æ¸‰å±¥æ­´CSV

å…¥åŠ›ï¼š
- å‰æ—¥ã®ã‚³ãƒ¼ãƒ«ã‚»ãƒ³ã‚¿ãƒ¼å›åå§”è¨—æƒ…å ±ï¼ˆExcelï¼‰
- å½“æ—¥ã®ã‚³ãƒ¼ãƒ«ã‚»ãƒ³ã‚¿ãƒ¼å›åå§”è¨—æƒ…å ±ï¼ˆExcelï¼‰
- 1241ä»¶.csvï¼ˆãƒ—ãƒ©ã‚¶ä¾é ¼åˆ†ãƒªã‚¹ãƒˆï¼‰

å‡¦ç†ãƒ•ãƒ­ãƒ¼ï¼š
1. å‰æ—¥ã¨å½“æ—¥ã®å»¶æ»é¡åˆè¨ˆã‚’æ¯”è¼ƒã—ã¦å…¥é‡‘é¡ã‚’ç®—å‡º
2. ä¼šå“¡ç•ªå·ã¨å¼•ç¶™ç•ªå·ã‚’ãƒãƒƒãƒãƒ³ã‚°ã—ã¦ç®¡ç†ç•ªå·ã‚’å–å¾—
3. 2ã¤ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
"""

import pandas as pd
import io
from datetime import datetime
from typing import Tuple, List, Dict, Any
from processors.common.detailed_logger import DetailedLogger
from processors.sms_common.utils import read_csv_auto_encoding
from processors.common.plaza_debt_columns import PlazaDebtUpdateColumns as PDC


def process_plaza_debt_update(
    yesterday_file: bytes,
    today_file: bytes,
    plaza_list_file: bytes,
    selected_date: datetime.date
) -> Tuple[List[pd.DataFrame], List[str], List[str], Dict[str, Any]]:
    """
    ãƒ—ãƒ©ã‚¶æ®‹å‚µæ›´æ–°å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°
    
    Args:
        yesterday_file: å‰æ—¥ã®ã‚³ãƒ¼ãƒ«ã‚»ãƒ³ã‚¿ãƒ¼å›åå§”è¨—æƒ…å ±ï¼ˆExcelï¼‰
        today_file: å½“æ—¥ã®ã‚³ãƒ¼ãƒ«ã‚»ãƒ³ã‚¿ãƒ¼å›åå§”è¨—æƒ…å ±ï¼ˆExcelï¼‰
        plaza_list_file: 1241ä»¶.csvï¼ˆãƒ—ãƒ©ã‚¶ä¾é ¼åˆ†ãƒªã‚¹ãƒˆï¼‰
        selected_date: äº¤æ¸‰å‚™è€ƒã«ä½¿ç”¨ã™ã‚‹æ—¥ä»˜
    
    Returns:
        tuple: (å‡ºåŠ›DataFrameã®ãƒªã‚¹ãƒˆ, ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒªã‚¹ãƒˆ, ãƒ­ã‚°ãƒªã‚¹ãƒˆ, çµ±è¨ˆæƒ…å ±)
    """
    logs = []
    
    try:
        # === ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ ===
        logs.append("ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿é–‹å§‹...")
        
        # å‰æ—¥ã®Excelãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        df_yesterday = pd.read_excel(
            io.BytesIO(yesterday_file),
            usecols=[
                PDC.COLLECTION_REPORT['member_no']['name'],
                PDC.COLLECTION_REPORT['arrears_total']['name']
            ]
        )
        logs.append(f"å‰æ—¥ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df_yesterday)}ä»¶")
        
        # å½“æ—¥ã®Excelãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        df_today = pd.read_excel(
            io.BytesIO(today_file),
            usecols=[
                PDC.COLLECTION_REPORT['member_no']['name'],
                PDC.COLLECTION_REPORT['arrears_total']['name'],
                PDC.COLLECTION_REPORT['report_source']['name'],
                PDC.COLLECTION_REPORT['cancellation_date']['name'],
                PDC.COLLECTION_REPORT['move_out_date']['name']
            ]
        )
        logs.append(f"å½“æ—¥ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df_today)}ä»¶")
        
        # 1241ä»¶.csvã®èª­ã¿è¾¼ã¿
        df_plaza_list = read_csv_auto_encoding(plaza_list_file)
        logs.append(f"ãƒ—ãƒ©ã‚¶ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿: {len(df_plaza_list)}ä»¶")
        
        # === ãƒ‡ãƒ¼ã‚¿å‡¦ç† ===
        logs.append("ğŸ”„ ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–‹å§‹...")
        
        # ä¼šå“¡ç•ªå·ã‚’æ–‡å­—åˆ—å‹ã«çµ±ä¸€ï¼ˆãƒãƒ¼ã‚¸ã‚¨ãƒ©ãƒ¼å¯¾ç­–ï¼‰
        member_no_col = PDC.COLLECTION_REPORT['member_no']['name']
        df_yesterday[member_no_col] = df_yesterday[member_no_col].astype(str).str.strip()
        df_today[member_no_col] = df_today[member_no_col].astype(str).str.strip()
        logs.append("âœ… ä¼šå“¡ç•ªå·ã®ãƒ‡ãƒ¼ã‚¿å‹ã‚’çµ±ä¸€ï¼ˆæ–‡å­—åˆ—å‹ï¼‰")
        
        # å‰æ—¥ãƒ‡ãƒ¼ã‚¿ã¨ã®ãƒãƒ¼ã‚¸ï¼ˆVLOOKUPã®å®Ÿè£…ï¼‰
        df_merged = df_today.merge(
            df_yesterday[[
                PDC.COLLECTION_REPORT['member_no']['name'],
                PDC.COLLECTION_REPORT['arrears_total']['name']
            ]],
            on=PDC.COLLECTION_REPORT['member_no']['name'],
            how='left',
            suffixes=('_å½“æ—¥', '_å‰æ—¥')
        )
        
        # å…¥é‡‘é¡ã®è¨ˆç®—
        arrears_today = PDC.COLLECTION_REPORT['arrears_total']['name'] + '_å½“æ—¥'
        arrears_yesterday = PDC.COLLECTION_REPORT['arrears_total']['name'] + '_å‰æ—¥'
        
        # æ•°å€¤å‹ã«å¤‰æ›
        df_merged[arrears_today] = pd.to_numeric(df_merged[arrears_today], errors='coerce').fillna(0)
        df_merged[arrears_yesterday] = pd.to_numeric(df_merged[arrears_yesterday], errors='coerce').fillna(0)
        
        # å…¥é‡‘é¡è¨ˆç®—ï¼ˆå‰æ—¥ - å½“æ—¥ï¼‰
        df_merged['å…¥é‡‘é¡'] = df_merged[arrears_yesterday] - df_merged[arrears_today]
        
        # å…¥é‡‘é¡ã®åˆ†æãƒ­ã‚°
        positive_payments = df_merged[df_merged['å…¥é‡‘é¡'] > 0]
        zero_payments = df_merged[df_merged['å…¥é‡‘é¡'] == 0]
        negative_payments = df_merged[df_merged['å…¥é‡‘é¡'] < 0]
        
        logs.append(f"ğŸ’° å…¥é‡‘é¡åˆ†æ:")
        logs.append(f"  - å…¥é‡‘ã‚ã‚Š: {len(positive_payments)}ä»¶ (ç·é¡: {positive_payments['å…¥é‡‘é¡'].sum():,}å††)")
        logs.append(f"  - å¤‰å‹•ãªã—: {len(zero_payments)}ä»¶")
        logs.append(f"  - æ®‹å‚µå¢—åŠ : {len(negative_payments)}ä»¶ (ç·é¡: {negative_payments['å…¥é‡‘é¡'].sum():,}å††)")
        
        # ç•°å¸¸å€¤ã®æ¤œå‡ºï¼ˆå…¥é‡‘é¡ãŒå¤§ãã™ãã‚‹/å°ã•ã™ãã‚‹ã‚±ãƒ¼ã‚¹ï¼‰
        large_payments = df_merged[df_merged['å…¥é‡‘é¡'] > 1000000]  # 100ä¸‡å††ä»¥ä¸Š
        if len(large_payments) > 0:
            logs.append(f"  - é«˜é¡å…¥é‡‘ï¼ˆ100ä¸‡å††ä»¥ä¸Šï¼‰: {len(large_payments)}ä»¶")
        
        # ãƒãƒƒãƒãƒ³ã‚°çŠ¶æ³ã‚’ãƒ­ã‚°
        before_match = len(df_merged)
        matched_count = df_merged[arrears_yesterday].notna().sum()
        unmatched_count = before_match - matched_count
        
        logs.append(DetailedLogger.log_filter_result(
            before_match,
            matched_count,
            "å‰æ—¥ãƒ‡ãƒ¼ã‚¿ã¨ã®ãƒãƒƒãƒãƒ³ã‚°"
        ))
        
        # ãƒãƒƒãƒã—ãªã‹ã£ãŸä¼šå“¡ç•ªå·ã®è©³ç´°
        if unmatched_count > 0:
            unmatched_data = df_merged[df_merged[arrears_yesterday].isna()]
            unmatched_ids = unmatched_data[PDC.COLLECTION_REPORT['member_no']['name']].head(10).tolist()
            logs.append(f"  - å‰æ—¥ãƒ‡ãƒ¼ã‚¿ã«ãªã„ä¼šå“¡ç•ªå·ï¼ˆæœ€å¤§10ä»¶ï¼‰: {unmatched_ids}")
            if unmatched_count > 10:
                logs.append(f"  - ä»–{unmatched_count - 10}ä»¶")
        
        # å¼•ç¶™ç•ªå·ã‚‚æ–‡å­—åˆ—å‹ã«çµ±ä¸€
        takeover_no_col = PDC.PLAZA_LIST['takeover_no']['name']
        df_plaza_list[takeover_no_col] = df_plaza_list[takeover_no_col].astype(str).str.strip()
        logs.append("âœ… å¼•ç¶™ç•ªå·ã®ãƒ‡ãƒ¼ã‚¿å‹ã‚’çµ±ä¸€ï¼ˆæ–‡å­—åˆ—å‹ï¼‰")
        
        # ãƒ‡ãƒãƒƒã‚°ï¼šãƒãƒƒãƒãƒ³ã‚°å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤º
        logs.append("ğŸ“Š ãƒãƒƒãƒãƒ³ã‚°ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
        logs.append(f"  - ä¼šå“¡ç•ªå·ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€åˆã®5ä»¶ï¼‰: {df_merged[member_no_col].head().tolist()}")
        logs.append(f"  - å¼•ç¶™ç•ªå·ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€åˆã®5ä»¶ï¼‰: {df_plaza_list[takeover_no_col].head().tolist()}")
        
        # ä¼šå“¡ç•ªå·ã¨å¼•ç¶™ç•ªå·ã®å…±é€šå€¤ã‚’ç¢ºèª
        common_values = set(df_merged[member_no_col]).intersection(set(df_plaza_list[takeover_no_col]))
        logs.append(f"  - å…±é€šã™ã‚‹å€¤ã®æ•°: {len(common_values)}ä»¶")
        if len(common_values) > 0:
            logs.append(f"  - å…±é€šå€¤ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€å¤§5ä»¶ï¼‰: {list(common_values)[:5]}")
        
        # ç®¡ç†ç•ªå·ã®å–å¾—ï¼ˆ1241ä»¶.csvã¨ã®ãƒãƒƒãƒãƒ³ã‚°ï¼‰
        df_merged = df_merged.merge(
            df_plaza_list[[
                PDC.PLAZA_LIST['takeover_no']['name'],
                PDC.PLAZA_LIST['management_no']['name']
            ]],
            left_on=PDC.COLLECTION_REPORT['member_no']['name'],
            right_on=PDC.PLAZA_LIST['takeover_no']['name'],
            how='left'
        )
        
        # ãƒãƒƒãƒãƒ³ã‚°çŠ¶æ³ã‚’ãƒ­ã‚°
        management_matched = df_merged[PDC.PLAZA_LIST['management_no']['name']].notna().sum()
        management_unmatched = len(df_merged) - management_matched
        
        logs.append(DetailedLogger.log_filter_result(
            len(df_merged),
            management_matched,
            "ç®¡ç†ç•ªå·ã¨ã®ãƒãƒƒãƒãƒ³ã‚°"
        ))
        
        # ãƒãƒƒãƒã—ãªã‹ã£ãŸå¼•ç¶™ç•ªå·ã®è©³ç´°
        if management_unmatched > 0:
            unmatched_data = df_merged[df_merged[PDC.PLAZA_LIST['management_no']['name']].isna()]
            unmatched_ids = unmatched_data[PDC.COLLECTION_REPORT['member_no']['name']].head(10).tolist()
            logs.append(f"  - ç®¡ç†ç•ªå·ãŒè¦‹ã¤ã‹ã‚‰ãªã„ä¼šå“¡ç•ªå·ï¼ˆæœ€å¤§10ä»¶ï¼‰: {unmatched_ids}")
            if management_unmatched > 10:
                logs.append(f"  - ä»–{management_unmatched - 10}ä»¶")
        
        # === å‡ºåŠ›1: ç®¡ç†å‰æ»ç´é¡æƒ…å ±CSV ===
        output1 = pd.DataFrame({
            PDC.LATE_PAYMENT_OUTPUT_HEADERS[0]: df_merged[PDC.PLAZA_LIST['management_no']['name']].fillna(''),
            PDC.LATE_PAYMENT_OUTPUT_HEADERS[1]: df_merged[arrears_today].astype(int)
        })
        
        # === å‡ºåŠ›2: äº¤æ¸‰å±¥æ­´CSV ===
        # å…¥é‡‘ãŒã‚ã£ãŸäººã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        df_with_payment = df_merged[df_merged['å…¥é‡‘é¡'] > 0].copy()
        logs.append(f"äº¤æ¸‰å±¥æ­´å‡ºåŠ›å¯¾è±¡: {len(df_with_payment)}ä»¶ï¼ˆå…¥é‡‘é¡ > 0å††ï¼‰")
        
        # äº¤æ¸‰å‚™è€ƒã®ç”Ÿæˆï¼ˆé¸æŠã—ãŸæ—¥ä»˜ã‚’ä½¿ç”¨ï¼‰
        selected_date_str = selected_date.strftime('%Y/%m/%d')
        
        def create_negotiation_note(row):
            """äº¤æ¸‰å‚™è€ƒã®æ–‡å­—åˆ—ã‚’ç”Ÿæˆ"""
            payment = int(row['å…¥é‡‘é¡'])
            balance = int(row[arrears_today])
            return f"{selected_date_str}ã€€{payment:,}å††å…¥é‡‘ã‚ã‚Šï¼ˆç¾æ®‹å‚µ{balance:,}å††ï¼‰"
        
        # Båˆ—äº¤æ¸‰æ—¥æ™‚ç”¨ï¼ˆä»Šæ—¥ã®æ—¥ä»˜ï¼‰
        today_str = datetime.now().strftime('%Y/%m/%d')
        
        # äº¤æ¸‰å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆï¼ˆå…¥é‡‘ãŒã‚ã£ãŸäººã®ã¿ï¼‰
        output2 = pd.DataFrame({
            PDC.NEGOTIATES_OUTPUT_HEADERS[0]: df_with_payment[PDC.PLAZA_LIST['management_no']['name']].fillna(''),
            PDC.NEGOTIATES_OUTPUT_HEADERS[1]: today_str,
            PDC.NEGOTIATES_OUTPUT_HEADERS[2]: PDC.NEGOTIATES_FIXED_VALUES['æ‹…å½“'],
            PDC.NEGOTIATES_OUTPUT_HEADERS[3]: PDC.NEGOTIATES_FIXED_VALUES['ç›¸æ‰‹'],
            PDC.NEGOTIATES_OUTPUT_HEADERS[4]: PDC.NEGOTIATES_FIXED_VALUES['æ‰‹æ®µ'],
            PDC.NEGOTIATES_OUTPUT_HEADERS[5]: PDC.NEGOTIATES_FIXED_VALUES['å›åãƒ©ãƒ³ã‚¯'],
            PDC.NEGOTIATES_OUTPUT_HEADERS[6]: PDC.NEGOTIATES_FIXED_VALUES['çµæœ'],
            PDC.NEGOTIATES_OUTPUT_HEADERS[7]: PDC.NEGOTIATES_FIXED_VALUES['å…¥é‡‘äºˆå®š'],
            PDC.NEGOTIATES_OUTPUT_HEADERS[8]: PDC.NEGOTIATES_FIXED_VALUES['äºˆå®šé‡‘é¡'],
            PDC.NEGOTIATES_OUTPUT_HEADERS[9]: df_with_payment.apply(create_negotiation_note, axis=1)
        })
        
        # === ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ ===
        date_str = datetime.now().strftime("%m%d")
        filename1 = f"{date_str}ãƒ—ãƒ©ã‚¶ç®¡ç†å‰æ»ç´é¡.csv"
        filename2 = f"{date_str}ãƒ—ãƒ©ã‚¶äº¤æ¸‰å±¥æ­´.csv"
        
        # === çµ±è¨ˆæƒ…å ± ===
        stats = {
            'total_records': len(df_merged),
            'management_matched': management_matched,
            'total_payment': df_merged['å…¥é‡‘é¡'].sum(),
            'positive_payments': (df_merged['å…¥é‡‘é¡'] > 0).sum(),
            'zero_payments': (df_merged['å…¥é‡‘é¡'] == 0).sum(),
            'negative_payments': (df_merged['å…¥é‡‘é¡'] < 0).sum()
        }
        
        logs.append(f"âœ… å‡¦ç†å®Œäº†")
        logs.append(f"ğŸ“Š æœ€çµ‚çµæœ: å½“æ—¥ãƒ‡ãƒ¼ã‚¿{len(df_today)}ä»¶ â†’ å‡¦ç†æ¸ˆã¿{len(df_merged)}ä»¶ â†’ ç®¡ç†ç•ªå·ä»˜ã{stats['management_matched']}ä»¶")
        
        return [output1, output2], [filename1, filename2], logs, stats
        
    except Exception as e:
        error_msg = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        logs.append(f"âŒ {error_msg}")
        raise Exception(error_msg)